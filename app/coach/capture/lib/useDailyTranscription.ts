import { useState, useCallback, useRef, useEffect } from 'react';
import { useUser } from '@clerk/nextjs';
import DailyIframe, { 
  DailyCall, 
  DailyEvent
} from '@daily-co/daily-js';

// Interface para blocos de transcri√ß√£o (Fase 2)
interface TranscriptionBlock {
  id: string; // Ex: `block-${Date.now()}`
  source: 'microphone' | 'screen' | 'remote';
  color: 'blue' | 'green' | 'gray';
  startTime: Date;
  text: string; // O texto consolidado do bloco
}

// Interface compat√≠vel com Deepgram (mantendo mesma estrutura) + Enhanced Dual Stream
export interface TranscriptionState {
  transcript: string;
  interimTranscript: string;
  isListening: boolean;
  isConnected: boolean;
  isProcessing: boolean;
  error: string | null;
  connectionQuality: 'good' | 'poor' | 'disconnected';
  audioLevel: number;
  wordsTranscribed: number;
  sessionDuration: number;
  lastActivity: Date | null;
  canForceFinalize: boolean;
  devicePermissions: {
    microphone: boolean;
    speaker: boolean;
  };
  availableDevices: {
    microphones: MediaDeviceInfo[];
    speakers: MediaDeviceInfo[];
  };
  selectedDeviceId: string | null;
  isScreenAudioCaptured: boolean;
  transcriptionLanguage: string;
  confidence: number;
  isPaused: boolean;
  segments: Array<{
    text: string;
    confidence: number;
    timestamp: Date;
    isFinal: boolean;
    audioSource: 'screen' | 'microphone' | 'remote';
    color: 'green' | 'blue' | 'gray';
    speakerId?: string; // NOVO: ID do speaker via diariza√ß√£o
    trackType?: 'audio' | 'screenAudio'; // NOVO: Tipo de track do Daily.co
  }>;
  blocks: TranscriptionBlock[]; // NOVO: Sistema de blocos (Fase 2)
  // NOVOS CAMPOS para Dual Stream Enhancement
  trackInfo: {
    audioTrackActive: boolean;
    screenAudioTrackActive: boolean;
    lastDetectedSource: 'microphone' | 'screen' | 'unknown';
  };
  diarizationEnabled: boolean;
  speakerStats: {
    microphoneSegments: number;
    screenSegments: number;
    totalSpeakers: number;
  };
  // NOVOS CAMPOS para Controles Independentes (Fase 2)
  isMicrophoneEnabled: boolean;
  isScreenAudioEnabled: boolean;
}

// Interface para configura√ß√£o Daily
interface DailyTranscriptionConfig {
  language?: string;
  model?: string;
  profanityFilter?: boolean;
  enableScreenAudio?: boolean;
  enableInterimResults?: boolean;
}

// Interface para eventos de transcri√ß√£o Daily
interface DailyTranscriptionMessage {
  type: 'transcription-message';
  sessionId: string;
  participantId: string;
  text: string;
  timestamp: string;
  is_final: boolean;
  confidence?: number;
  language?: string;
}

// Fun√ß√£o para diagnosticar disponibilidade de APIs
const checkMediaDevicesSupport = () => {
  const support = {
    mediaDevices: !!navigator.mediaDevices,
    getUserMedia: !!(navigator.mediaDevices?.getUserMedia),
    enumerateDevices: !!(navigator.mediaDevices?.enumerateDevices),
    addEventListener: !!(navigator.mediaDevices?.addEventListener),
    isSecureContext: !!window.isSecureContext,
    protocol: window.location.protocol
  };
  
  console.log('üìã Diagn√≥stico MediaDevices:', support);
  return support;
};

export const useDailyTranscription = (config?: DailyTranscriptionConfig) => {
  // Hook para acessar dados do usu√°rio Clerk
  const { user, isLoaded: isUserLoaded } = useUser();

  // Diagn√≥stico inicial - executar apenas uma vez
  useEffect(() => {
    checkMediaDevicesSupport();
  }, []);

  // Estados principais compat√≠veis com Deepgram + Enhanced Dual Stream
  const [state, setState] = useState<TranscriptionState>({
    transcript: '',
    interimTranscript: '',
    isListening: false,
    isConnected: false,
    isProcessing: false,
    error: null,
    connectionQuality: 'disconnected',
    audioLevel: 0,
    wordsTranscribed: 0,
    sessionDuration: 0,
    lastActivity: null,
    canForceFinalize: true,
    devicePermissions: {
      microphone: false,
      speaker: false
    },
    availableDevices: {
      microphones: [],
      speakers: []
    },
    selectedDeviceId: null,
    isScreenAudioCaptured: false,
    transcriptionLanguage: config?.language || 'pt',
    confidence: 0,
    isPaused: false,
    segments: [],
    blocks: [], // NOVO: Sistema de blocos inicializado (Fase 2)
    // NOVOS CAMPOS INICIALIZADOS
    trackInfo: {
      audioTrackActive: false,
      screenAudioTrackActive: false,
      lastDetectedSource: 'unknown'
    },
    diarizationEnabled: true, // Ativado por padr√£o
    speakerStats: {
      microphoneSegments: 0,
      screenSegments: 0,
      totalSpeakers: 0
    },
    // NOVOS CAMPOS INICIALIZADOS (Fase 2)
    isMicrophoneEnabled: false, // Microfone inicia desligado
    isScreenAudioEnabled: true   // √Åudio da tela inicia ligado
  });

  // Refs para Daily.co
  const callObjectRef = useRef<DailyCall | null>(null);
  const roomNameRef = useRef<string | null>(null);
  const startTimeRef = useRef<Date | null>(null);
  const audioLevelIntervalRef = useRef<NodeJS.Timeout | null>(null);
  
  
  // Sistema de deduplica√ß√£o espec√≠fico para nosso contexto (1 usu√°rio, 2 canais)
  const processedMessagesRef = useRef<Map<string, number>>(new Map());
  const processedInterimRef = useRef<Map<string, number>>(new Map()); // Cache separado para interim
  const MESSAGE_CLEANUP_INTERVAL = 10000; // 10s cleanup

  // NOVA FUN√á√ÉO: Determinar fonte de √°udio - ESTRAT√âGIA BASEADA EM DADOS REAIS
  const determineAudioSourceAdvanced = useCallback((data: any, participants: any): {
    audioSource: 'screen' | 'microphone' | 'remote';
    trackType: 'audio' | 'screenAudio';
    confidence: number;
  } => {
    console.log('üî¨ Analisando dados para detec√ß√£o de fonte:', {
      hasTrackType: !!data.track_type,
      hasSpeakerId: !!(data.speaker_id || data.speaker),
      hasParticipantId: !!data.participant_id,
      screenCaptureActive: state.isScreenAudioCaptured,
      availableDataFields: Object.keys(data),
    });

    // 1. PRIMEIRO: Verificar se h√° informa√ß√µes diretas de track no evento
    if (data.track_type) {
      const trackType = data.track_type as 'audio' | 'screenAudio';
      console.log('‚úÖ Fonte detectada via track_type:', trackType);
      return {
        audioSource: trackType === 'screenAudio' ? 'screen' : 'microphone',
        trackType,
        confidence: 0.95
      };
    }

    // 2. SEGUNDO: Usar diariza√ß√£o (speaker ID) se dispon√≠vel
    if (data.speaker_id || data.speaker) {
      const speakerId = data.speaker_id || data.speaker;
      console.log('üé≠ Tentando detectar fonte via speaker ID:', speakerId);
      
      // Estrat√©gia: speaker IDs diferentes = fontes diferentes
      // Speaker 0 ou primeiro = microfone, Speaker 1+ = tela
      const isFirstSpeaker = speakerId === '0' || speakerId === 0 || speakerId === 'speaker_0';
      
      if (state.isScreenAudioCaptured && !isFirstSpeaker) {
        return {
          audioSource: 'screen',
          trackType: 'screenAudio',
          confidence: 0.8
        };
      }
    }

    // 3. TERCEIRO: An√°lise de tracks se dispon√≠vel
    const localParticipant = participants?.local;
    if (localParticipant?.tracks) {
      const audioTrack = localParticipant.tracks.audio;
      const screenAudioTrack = localParticipant.tracks.screenAudio;
      
      const audioActive = audioTrack?.state === 'sendable' || audioTrack?.state === 'loading';
      const screenAudioActive = screenAudioTrack?.state === 'sendable' || screenAudioTrack?.state === 'loading';
      
      console.log('üéµ Status dos tracks:', { audioActive, screenAudioActive });
      
      // Atualizar trackInfo no estado
      setState(prev => ({
        ...prev,
        trackInfo: {
          audioTrackActive: audioActive,
          screenAudioTrackActive: screenAudioActive,
          lastDetectedSource: screenAudioActive && state.isScreenAudioCaptured ? 'screen' : 'microphone'
        }
      }));
      
      // Se apenas screen audio est√° ativo
      if (screenAudioActive && !audioActive && state.isScreenAudioCaptured) {
        return {
          audioSource: 'screen',
          trackType: 'screenAudio',
          confidence: 0.9
        };
      }
    }

    // 4. QUARTO: Fallback inteligente para dual stream
    if (state.isScreenAudioCaptured) {
      console.log('üîÑ Usando fallback para dual stream');
      
      // Estrat√©gia baseada em caracter√≠sticas do texto ou timestamp
      const textLength = data.text?.length || 0;
      const isLongText = textLength > 30; // Textos longos podem ser da tela (leitura)
      const timestampBased = Math.floor(Date.now() / 2000) % 2 === 0; // Alternar a cada 2 segundos
      
      // Combina√ß√£o de fatores
      const isScreenSource = isLongText || timestampBased;
      
      return {
        audioSource: isScreenSource ? 'screen' : 'microphone',
        trackType: isScreenSource ? 'screenAudio' : 'audio',
        confidence: 0.6
      };
    }

    // 5. FINAL: Default para microfone
    console.log('üé§ Defaulting para microfone');
    return {
      audioSource: 'microphone',
      trackType: 'audio',
      confidence: 0.8
    };
  }, [state.isScreenAudioCaptured]);

  // Atualizar dura√ß√£o da sess√£o
  useEffect(() => {
    let interval: NodeJS.Timeout;
    
    if (state.isListening && startTimeRef.current) {
      interval = setInterval(() => {
        const now = new Date();
        const duration = Math.floor((now.getTime() - startTimeRef.current!.getTime()) / 1000);
        setState(prev => ({ ...prev, sessionDuration: duration }));
      }, 1000);
    }
    
    return () => {
      if (interval) clearInterval(interval);
    };
  }, [state.isListening]);

  // Fun√ß√£o para obter permiss√µes de m√≠dia
  const requestPermissions = useCallback(async () => {
    try {
      // Verificar se getUserMedia est√° dispon√≠vel
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        console.error('‚ùå getUserMedia n√£o dispon√≠vel - verifique se est√° em HTTPS');
        setState(prev => ({
          ...prev,
          error: 'Acesso ao microfone n√£o dispon√≠vel (necess√°rio HTTPS)',
          devicePermissions: {
            ...prev.devicePermissions,
            microphone: false
          }
        }));
        return false;
      }

      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: true,
        video: false 
      });
      
      stream.getTracks().forEach(track => track.stop());
      
      setState(prev => ({
        ...prev,
        devicePermissions: {
          ...prev.devicePermissions,
          microphone: true
        }
      }));
      
      return true;
    } catch (error) {
      console.error('‚ùå Erro ao obter permiss√µes:', error);
      setState(prev => ({
        ...prev,
        error: 'Permiss√£o de microfone negada ou n√£o dispon√≠vel',
        devicePermissions: {
          ...prev.devicePermissions,
          microphone: false
        }
      }));
      
      return false;
    }
  }, []);

  // Fun√ß√£o para listar dispositivos dispon√≠veis
  const updateAvailableDevices = useCallback(async () => {
    try {
      // Verificar se mediaDevices est√° dispon√≠vel
      if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {
        console.warn('‚ö†Ô∏è navigator.mediaDevices n√£o dispon√≠vel');
        return;
      }

      const devices = await navigator.mediaDevices.enumerateDevices();
      
      setState(prev => ({
        ...prev,
        availableDevices: {
          microphones: devices.filter(d => d.kind === 'audioinput'),
          speakers: devices.filter(d => d.kind === 'audiooutput')
        }
      }));
    } catch (error) {
      console.error('‚ùå Erro ao listar dispositivos:', error);
    }
  }, []);

  // Monitorar n√≠vel de √°udio
  const startAudioLevelMonitoring = useCallback((callObject: DailyCall) => {
    if (audioLevelIntervalRef.current) {
      clearInterval(audioLevelIntervalRef.current);
    }

    audioLevelIntervalRef.current = setInterval(async () => {
      try {
        const stats = await callObject.getNetworkStats();
        const localAudio = stats?.stats?.latest?.recvBitsPerSecond || 0;
        
        setState(prev => ({
          ...prev,
          audioLevel: Math.min(100, Math.max(0, localAudio / 1000)) // Converter para 0-100
        }));
      } catch (error) {
        // Silencioso - estat√≠sticas podem n√£o estar dispon√≠veis
      }
    }, 100);
  }, []);

  // Handler otimizado para transcri√ß√£o iniciada
  const handleTranscriptionStarted = useCallback((event: any) => {
    console.log('‚úÖ Transcri√ß√£o Daily.co iniciada:', event);
    setState(prev => ({ 
      ...prev, 
      isProcessing: true,
      lastActivity: new Date()
    }));
  }, []);

  // Handler otimizado para erro de transcri√ß√£o COM RETRY
  const handleTranscriptionError = useCallback(async (event: any) => {
    console.error('‚ùå Erro de transcri√ß√£o:', event);
    
    // Se for erro 403, tentar com configura√ß√£o ainda mais simples
    if (event.errorMsg?.includes('403') || event.errorMsg?.includes('Unexpected server response')) {
      console.log('üîÑ Tentando reconectar com configura√ß√£o b√°sica...');
      
      try {
        const callObject = callObjectRef.current;
        if (callObject) {
          // Aguardar um pouco antes da tentativa
          await new Promise(resolve => setTimeout(resolve, 1000));
          
          // Configura√ß√£o m√≠nima v√°lida
          const basicConfig = {
            language: 'pt-BR',
            model: 'nova-2-general'
          };
          
          await callObject.startTranscription(basicConfig);
          
          setState(prev => ({
            ...prev,
            error: 'Reconectado com configura√ß√£o b√°sica - diariza√ß√£o limitada',
            isListening: true,
            isProcessing: false
          }));
          
          console.log('‚úÖ Reconectado com configura√ß√£o b√°sica');
          return;
        }
      } catch (retryError) {
        console.error('‚ùå Falha na reconex√£o:', retryError);
      }
    }
    
    setState(prev => ({
      ...prev,
      error: `Erro de transcri√ß√£o: ${event.errorMsg || 'Erro desconhecido'}`,
      isListening: false,
      isProcessing: false
    }));
  }, []);

  // Sistema de deduplica√ß√£o para nosso contexto espec√≠fico
  const isDuplicateMessage = useCallback((data: any) => {
    const now = Date.now();
    const isInterim = !data.is_final;
    
    // Gerar chave √∫nica baseada no conte√∫do e contexto
    // Para nosso caso: 1 usu√°rio com 2 canais (microfone + tela)
    const messageKey = `${data.text?.trim()}_${data.is_final ? 'final' : 'interim'}_${data.timestamp || now}`;
    
    // Para mensagens interim, usar cache separado com chave mais espec√≠fica
    if (isInterim) {
      // Chave espec√≠fica para interim: conte√∫do + timestamp (mais sens√≠vel)
      const interimKey = `${data.text?.trim()}_interim`;
      
      if (processedInterimRef.current.has(interimKey)) {
        console.log('üîÑ Mensagem interim duplicada ignorada:', interimKey.substring(0, 50) + '...');
        return true;
      }
      
      // Limpar cache interim anterior (manter apenas o mais recente)
      processedInterimRef.current.clear();
      processedInterimRef.current.set(interimKey, now);
      
      return false;
    }
    
    // Para mensagens finais, usar cache normal
    if (processedMessagesRef.current.has(messageKey)) {
      console.log('üîÑ Mensagem final duplicada ignorada:', messageKey.substring(0, 50) + '...');
      return true;
    }
    
    // Adicionar ao cache de mensagens processadas
    processedMessagesRef.current.set(messageKey, now);
    
    // Cleanup autom√°tico - remover mensagens antigas (>10s)
    const cutoffTime = now - MESSAGE_CLEANUP_INTERVAL;
    for (const [key, timestamp] of Array.from(processedMessagesRef.current.entries())) {
      if (timestamp < cutoffTime) {
        processedMessagesRef.current.delete(key);
      }
    }
    
    return false;
  }, []);

  // Handler otimizado para mensagem de transcri√ß√£o com deduplica√ß√£o
  const handleTranscriptionMessage = useCallback((data: any) => {
    const startTime = performance.now();
    
    // Verificar duplicata antes de processar
    if (isDuplicateMessage(data)) {
      return; // Ignorar mensagem duplicada
    }
    
    console.log('üìù Transcri√ß√£o processada (√∫nica):', data);
    
    // DEBUG INTENSIVO: Analisar TODOS os dados dispon√≠veis
    const participants = callObjectRef.current?.participants();
    
    console.log('üîç DEBUG COMPLETO - Dados brutos:', {
      rawData: data,
      dataKeys: Object.keys(data),
      dataValues: Object.values(data),
      participantsExists: !!participants,
      localParticipant: participants?.local,
      localTracks: participants?.local?.tracks,
      isScreenCaptured: state.isScreenAudioCaptured,
      callObjectMethods: callObjectRef.current 
        ? (() => {
            const callObject = callObjectRef.current;
            if (!callObject) return [];
            return Object.getOwnPropertyNames(callObject)
              .filter(name => {
                const descriptor = Object.getOwnPropertyDescriptor(callObject, name);
                return descriptor && typeof descriptor.value === 'function';
              })
              .slice(0, 10);
          })()
        : []
    });
    
    // NOVA ESTRAT√âGIA: Usar fun√ß√£o avan√ßada de detec√ß√£o de fonte
    const sourceAnalysis = determineAudioSourceAdvanced(data, participants);
    
    const audioSource = sourceAnalysis.audioSource;
    const trackType = sourceAnalysis.trackType;
    const detectionConfidence = sourceAnalysis.confidence;
    
    const color: 'green' | 'blue' | 'gray' = 
      audioSource === 'screen' ? 'green' : 
      audioSource === 'microphone' ? 'blue' : 'gray';
    

    console.log('üìä Enhanced Debug Daily.co:', {
      data,
      sourceAnalysis,
      participants: participants?.local,
      trackInfo: state.trackInfo,
      speakerId: data.speaker_id || data.speaker,
      trackType: data.track_type,
      isScreenAudioCaptured: state.isScreenAudioCaptured,
      availableFields: Object.keys(data),
      participantTracks: participants?.local?.tracks
    });
    
    console.log(`üé§ Fonte detectada (Enhanced): ${audioSource} (${trackType}) - Confian√ßa: ${(detectionConfidence * 100).toFixed(1)}%`);
    
    const newSegment = {
      text: data.text,
      confidence: data.confidence || 0,
      timestamp: new Date(),
      isFinal: data.is_final || false,
      audioSource,
      color,
      speakerId: data.speaker_id || data.speaker || 'unknown', // NOVO: Speaker ID da diariza√ß√£o
      trackType // NOVO: Tipo de track detectado
    };

    setState(prev => {
      const updatedSegments = [...prev.segments, newSegment];
      
      // NOVO: Atualizar estat√≠sticas de speakers
      const newStats = {
        microphoneSegments: prev.speakerStats.microphoneSegments + (audioSource === 'microphone' ? 1 : 0),
        screenSegments: prev.speakerStats.screenSegments + (audioSource === 'screen' ? 1 : 0),
        totalSpeakers: new Set([...prev.segments.map(s => s.speakerId), newSegment.speakerId]).size
      };
      
      if (data.is_final) {
        // FASE 4: L√≥gica de Separa√ß√£o - Criando Novos Blocos
        const lastBlock = prev.blocks[prev.blocks.length - 1];
        let updatedBlocks;
        
        // Verifica√ß√µes para cria√ß√£o de novo bloco
        const shouldCreateNewBlock = !lastBlock || 
                                   lastBlock.source !== audioSource || 
                                   lastBlock.text.length > 500;
        
        if (shouldCreateNewBlock) {
          // CONDI√á√ÉO ATINGIDA: Criar um NOVO bloco
          const newBlock: TranscriptionBlock = {
            id: `block-${Date.now()}`,
            source: audioSource,
            color: color,
            startTime: new Date(),
            text: data.text
          };
          updatedBlocks = [...prev.blocks, newBlock];
          
          // Logs espec√≠ficos da Fase 4
          if (!lastBlock) {
            console.log('üÜï Criado primeiro bloco:', newBlock);
          } else if (lastBlock.source !== audioSource) {
            console.log('üîÑ Novo bloco criado - mudan√ßa de fonte:', {
              anterior: lastBlock.source,
              nova: audioSource,
              novoBloco: newBlock
            });
          } else if (lastBlock.text.length > 500) {
            console.log('üìè Novo bloco criado - limite de 500 caracteres atingido:', {
              tamanhoAnterior: lastBlock.text.length,
              novoBloco: newBlock
            });
          }
        } else {
          // CONDI√á√ÉO N√ÉO ATINGIDA: Anexar ao bloco existente
          const updatedBlock = {
            ...lastBlock,
            text: lastBlock.text + (lastBlock.text ? ' ' : '') + data.text
          };
          updatedBlocks = [...prev.blocks.slice(0, -1), updatedBlock];
          console.log('üìù Texto anexado ao bloco existente:', {
            tamanhoAtual: updatedBlock.text.length,
            fonte: updatedBlock.source,
            bloco: updatedBlock
          });
        }
        
        // Log para debug da Fase 4
        console.log('üîç Estado dos blocos (Fase 4):', JSON.stringify(updatedBlocks, null, 2));
        
        // Texto final - adicionar ao transcript principal
        const finalText = prev.transcript + (prev.transcript ? ' ' : '') + data.text;
        
        return {
          ...prev,
          transcript: finalText,
          interimTranscript: '', // Limpar interim
          segments: updatedSegments,
          blocks: updatedBlocks, // NOVO: Atualizar blocos
          wordsTranscribed: finalText.split(' ').length,
          lastActivity: new Date(),
          confidence: data.confidence || 0,
          speakerStats: newStats // NOVO: Estat√≠sticas atualizadas
        };
      } else {
        // Resultado interim - apenas atualizar interimTranscript (sem duplica√ß√£o visual)
        return {
          ...prev,
          interimTranscript: data.text,
          segments: updatedSegments,
          lastActivity: new Date(),
          confidence: data.confidence || 0,
          speakerStats: newStats // NOVO: Estat√≠sticas atualizadas
        };
      }
    });
    
    const endTime = performance.now();
    const processingTime = endTime - startTime;
    console.log(`‚ö° Tempo de processamento: ${processingTime.toFixed(2)}ms`);
  }, [isDuplicateMessage]);

  // Handlers de eventos Daily.co com performance otimizada
  const setupDailyEventHandlers = useCallback((callObject: DailyCall) => {
    // Evento de participante entrou
    callObject.on('joined-meeting', () => {
      console.log('‚úÖ Conectado √† sala Daily.co');
      setState(prev => ({ 
        ...prev, 
        isConnected: true,
        connectionQuality: 'good',
        error: null
      }));
    });

    // Evento de erro com tratamento espec√≠fico para transport
    callObject.on('error', (event) => {
      console.error('‚ùå Erro Daily.co:', event);
      
      // Tratamento espec√≠fico para erro de transport disconnected
      if (event.errorMsg?.includes('transport') || event.errorMsg?.includes('disconnected')) {
        console.log('üîÑ Detectado erro de transport, tentando reconex√£o...');
        setState(prev => ({
          ...prev,
          error: 'Reconectando...',
          connectionQuality: 'poor'
        }));
        
        // Tentar reconex√£o ap√≥s delay
        setTimeout(async () => {
          try {
            if (callObjectRef.current && state.isListening) {
              console.log('üîÑ Reiniciando transcri√ß√£o ap√≥s erro de transport...');
              await callObjectRef.current.startTranscription({
                language: 'pt-BR',
                model: 'nova-2-general',
                profanity_filter: false,
                endpointing: 100,
                extra: {
                  interim_results: true,
                  punctuate: true,
                  utterance_end_ms: 1000
                }
              });
              setState(prev => ({ ...prev, error: null, connectionQuality: 'good' }));
              console.log('‚úÖ Transcri√ß√£o reconectada com sucesso');
            }
          } catch (reconnectError) {
            console.error('‚ùå Falha na reconex√£o:', reconnectError);
            setState(prev => ({
              ...prev,
              error: 'Falha na reconex√£o - tente reiniciar',
              isListening: false,
              isConnected: false,
              connectionQuality: 'disconnected'
            }));
          }
        }, 3000);
      } else {
        // Outros erros
        setState(prev => ({
          ...prev,
          error: `Erro Daily.co: ${event.errorMsg || 'Erro desconhecido'}`,
          isListening: false,
          isConnected: false,
          connectionQuality: 'disconnected'
        }));
      }
    });

    // Handlers espec√≠ficos ultra-r√°pidos
    callObject.on('transcription-started', handleTranscriptionStarted);
    callObject.on('transcription-error', handleTranscriptionError);
    
    // Evento de transcri√ß√£o parada
    callObject.on('transcription-stopped', (event) => {
      console.log('‚èπÔ∏è Transcri√ß√£o Daily.co parada:', event);
      setState(prev => ({ ...prev, isProcessing: false }));
    });

    // HANDLER PRIM√ÅRIO: Evento dedicado transcription-message (RECOMENDADO)
    callObject.on('transcription-message', (event) => {
      console.log('üìù Transcription-message (prim√°rio):', event);
      try {
        handleTranscriptionMessage(event);
      } catch (error) {
        console.error('‚ùå Erro ao processar transcription-message:', error);
      }
    });

    // HANDLER BACKUP: app-message para redund√¢ncia com fallback condicional
    // Nosso contexto: 1 usu√°rio, 2 canais - n√£o precisa filtro por session_id
    callObject.on('app-message', (event) => {
      // Filtro b√°sico para mensagens de transcri√ß√£o
      if (event.fromId !== 'transcription' || !event.data) return;
      
      console.log('üìù App-message (backup/fallback):', event.data);
      try {
        // Sistema de deduplica√ß√£o j√° trata duplicatas automaticamente
        // Permite redund√¢ncia sem duplica√ß√£o visual
        handleTranscriptionMessage(event.data);
      } catch (error) {
        console.error('‚ùå Erro ao processar app-message backup:', error);
      }
    });

    // Monitorar qualidade da conex√£o
    callObject.on('network-quality-change', (event) => {
      // Daily.co agora usa threshold ao inv√©s de quality
      const threshold = (event as any).threshold || event.quality;
      setState(prev => ({
        ...prev,
        connectionQuality: threshold > 0.5 ? 'good' : 'poor'
      }));
    });

    // Iniciar monitoramento de √°udio
    startAudioLevelMonitoring(callObject);
  }, [startAudioLevelMonitoring, handleTranscriptionStarted, handleTranscriptionError, handleTranscriptionMessage]);



  // Fun√ß√£o para iniciar transcri√ß√£o (compat√≠vel com Deepgram)
  const startListening = useCallback(async () => {
    try {
      setState(prev => ({ ...prev, error: null, isProcessing: true }));

      // Verificar se usu√°rio est√° carregado e logado
      if (!isUserLoaded || !user) {
        console.log('‚è≥ Aguardando dados do usu√°rio...');
        setState(prev => ({ ...prev, error: 'Aguardando autentica√ß√£o do usu√°rio', isProcessing: false }));
        return;
      }

      // Verificar permiss√µes de microfone
      const hasPermissions = await requestPermissions();
      if (!hasPermissions) {
        setState(prev => ({ ...prev, isProcessing: false }));
        return;
      }

      // 1. Verificar se j√° estamos conectados √† sala (reconex√£o)
      let callObject = callObjectRef.current;
      
      if (!callObject || !state.isConnected) {
        // Precisamos conectar √† sala primeiro
        
        // Criar sala com clerk-id
        const roomName = `transcription-${user.id}`;
        console.log(`üè† Verificando/criando sala persistente: ${roomName}`);

        // Verificar se sala j√° existe ou criar nova
        let roomData;
        try {
          const roomResponse = await fetch('/api/daily/rooms', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              roomName: roomName, // Nome espec√≠fico baseado no clerk ID
              language: config?.language || 'pt',
              transcriptionModel: config?.model || 'nova-2-general',
              enableTranscription: true
            })
          });

          if (!roomResponse.ok) {
            throw new Error('Erro ao criar/acessar sala Daily.co');
          }

          roomData = await roomResponse.json();
          roomNameRef.current = roomData.room.name;
          
          if (roomData.room.isExisting) {
            console.log(`üîÑ Reconectando √† sala existente: ${roomData.room.name}`);
          } else {
            console.log(`‚úÖ Nova sala criada: ${roomData.room.name}`);
          }

        } catch (error) {
          console.error('‚ùå Erro ao preparar sala:', error);
          setState(prev => ({ ...prev, error: 'Erro ao preparar sala de confer√™ncia', isProcessing: false }));
          return;
        }

        // Criar token de acesso
        const tokenResponse = await fetch('/api/daily/tokens', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            roomName: roomData.room.name,
            userName: `${user.firstName || 'Usuario'}-${user.id.slice(-6)}`,
            enableTranscription: true,
            permissions: {
              canScreenshare: config?.enableScreenAudio !== false
            }
          })
        });

        if (!tokenResponse.ok) {
          throw new Error('Erro ao criar token Daily.co');
        }

        const tokenData = await tokenResponse.json();

        // Criar CallObject Daily.co
        callObject = DailyIframe.createCallObject({
          audioSource: true,
          videoSource: false
        });

        callObjectRef.current = callObject;

        // Setup event handlers
        setupDailyEventHandlers(callObject);

        // Entrar na sala
        await callObject.join({
          url: roomData.room.url,
          token: tokenData.token,
          userName: tokenData.userName
        });

        console.log(`‚úÖ Conectado √† sala ${roomData.room.name}`);
        
        setState(prev => ({
          ...prev,
          isConnected: true
        }));
      }

      // 2. Iniciar transcri√ß√£o com configura√ß√£o V√ÅLIDA (removendo par√¢metros n√£o suportados)
      console.log('üé§ Iniciando transcri√ß√£o com diariza√ß√£o (configura√ß√£o corrigida)...');
      const transcriptionConfig = {
        language: 'pt-BR',
        model: 'nova-2-general',
        profanity_filter: false, // N√£o filtrar em contexto business
        diarize: true, // ATIVADO: Identifica diferentes speakers
        punctuate: true, // Pontua√ß√£o autom√°tica melhora legibilidade
        endpointing: 100, // CR√çTICO: Reduz lat√™ncia de 300ms para 100ms
        extra: {
          endpointing: 100,
          interim_results: true,
          punctuate: true,
          utterance_end_ms: 1000,
          diarize: true
          // Removidos par√¢metros n√£o suportados: tier, multichannel, speaker_labels, detect_language, filler_words
        }
      };
      
      await callObject.startTranscription(transcriptionConfig);

      // 3. Configurar compartilhamento de tela se solicitado
      if (config?.enableScreenAudio) {
        try {
          console.log('üñ•Ô∏è Iniciando compartilhamento de tela...');
          callObject.startScreenShare({
            audio: true // Capturar √°udio da tela
          });
          setState(prev => ({ ...prev, isScreenAudioCaptured: true }));
          console.log('‚úÖ Compartilhamento de tela ativo');
        } catch (screenError) {
          console.warn('‚ö†Ô∏è Compartilhamento de tela n√£o dispon√≠vel:', screenError);
        }
      }

      // 4. Configurar estado inicial do microfone (desligado conforme planejamento)
      if (callObject) {
        console.log('üé§ Configurando microfone inicial como DESLIGADO...');
        callObject.setLocalAudio(false); // Desligar microfone no in√≠cio
      }

      startTimeRef.current = new Date();
      setState(prev => ({
        ...prev,
        isListening: true,
        isProcessing: false,
        transcript: '',
        interimTranscript: '',
        segments: [],
        wordsTranscribed: 0,
        sessionDuration: 0,
        // Garantir que estado inicial do microfone est√° correto
        isMicrophoneEnabled: false // Confirma estado inicial
      }));

      console.log('‚úÖ Transcri√ß√£o Daily.co iniciada com sucesso');

    } catch (error) {
      console.error('‚ùå Erro ao iniciar Daily.co:', error);
      setState(prev => ({
        ...prev,
        error: error instanceof Error ? error.message : 'Erro ao iniciar transcri√ß√£o',
        isListening: false,
        isProcessing: false,
        isConnected: false
      }));
    }
  }, [user, isUserLoaded, state.isConnected, config, requestPermissions, setupDailyEventHandlers]);

  // Fun√ß√£o para parar transcri√ß√£o (compat√≠vel com Deepgram)
  const stopListening = useCallback(async () => {
    try {
      if (callObjectRef.current) {
        // Parar transcri√ß√£o
        await callObjectRef.current.stopTranscription();
        
        // Parar compartilhamento de tela se ativo
        if (state.isScreenAudioCaptured) {
          callObjectRef.current.stopScreenShare();
        }
        
        // Sair da sala
        await callObjectRef.current.leave();
        
        // Destruir call object
        callObjectRef.current.destroy();
        callObjectRef.current = null;
      }

      // Limpar intervalos
      if (audioLevelIntervalRef.current) {
        clearInterval(audioLevelIntervalRef.current);
        audioLevelIntervalRef.current = null;
      }

      setState(prev => ({
        ...prev,
        isListening: false,
        isConnected: false,
        isProcessing: false,
        connectionQuality: 'disconnected',
        audioLevel: 0,
        isScreenAudioCaptured: false
      }));

      console.log('‚úÖ Transcri√ß√£o Daily.co parada');

    } catch (error) {
      console.error('‚ùå Erro ao parar Daily.co:', error);
      setState(prev => ({
        ...prev,
        error: error instanceof Error ? error.message : 'Erro ao parar transcri√ß√£o'
      }));
    }
  }, [state.isScreenAudioCaptured]);

  // Pausar/retomar (compat√≠vel com Deepgram)
  const pauseListening = useCallback(async () => {
    // Daily.co n√£o tem pausa nativa, simular pausando o processamento
    setState(prev => ({ ...prev, isPaused: true }));
  }, []);

  const resumeListening = useCallback(async () => {
    setState(prev => ({ ...prev, isPaused: false }));
  }, []);

  // For√ßa finaliza√ß√£o (compat√≠vel com Deepgram)
  const forceFinalize = useCallback(async () => {
    if (callObjectRef.current && state.interimTranscript) {
      // Adicionar interim como final
      setState(prev => ({
        ...prev,
        transcript: prev.transcript + (prev.transcript ? ' ' : '') + prev.interimTranscript,
        interimTranscript: '',
        wordsTranscribed: (prev.transcript + ' ' + prev.interimTranscript).split(' ').length
      }));
    }
  }, [state.interimTranscript]);

  // Limpar estados (compat√≠vel com Deepgram)
  const clearTranscript = useCallback(() => {
    setState(prev => ({
      ...prev,
      transcript: '',
      interimTranscript: '',
      segments: [],
      wordsTranscribed: 0
    }));
  }, []);


  // NOVO: Fun√ß√£o de limpeza de hist√≥rico (preserva texto intermedi√°rio)
  const clearTranscriptionHistory = useCallback(() => {
    console.log('üßπ Limpando blocos finalizados. Texto intermedi√°rio ser√° preservado.');
    setState(prevState => ({
      ...prevState,
      blocks: [], // A√ß√£o principal: esvazia APENAS a lista de blocos.
      // O estado 'interimTranscript' e todos os outros s√£o intencionalmente preservados.
    }));
  }, []);

  // FASE 2: Fun√ß√µes de Controle de √Åudio Independentes
  
  // Fun√ß√£o para o microfone do usu√°rio
  const toggleMicrophone = useCallback(() => {
    const nextState = !state.isMicrophoneEnabled;
    callObjectRef.current?.setLocalAudio(nextState);
    setState(prev => ({ ...prev, isMicrophoneEnabled: nextState }));
    console.log(`üé§ Microfone foi ${nextState ? 'LIGADO' : 'DESLIGADO'}`);
  }, [state.isMicrophoneEnabled]);

  // Fun√ß√£o para o √°udio da tela
  const toggleScreenAudio = useCallback(() => {
    const nextState = !state.isScreenAudioEnabled;
    
    if (callObjectRef.current) {
      try {
        const participants = callObjectRef.current.participants();
        const localParticipant = participants?.local;
        const screenAudioTrack = localParticipant?.tracks?.screenAudio;
        
        if (nextState) {
          // Ligar √°udio da tela
          if (!state.isScreenAudioCaptured) {
            // Se screen share n√£o existe, iniciar com √°udio
            console.log('üñ•Ô∏è Iniciando compartilhamento de tela com √°udio...');
            callObjectRef.current.startScreenShare({ audio: true });
            setState(prev => ({ 
              ...prev, 
              isScreenAudioEnabled: true,
              isScreenAudioCaptured: true 
            }));
          } else if (screenAudioTrack?.track) {
            // Se screen share existe mas √°udio est√° mutado, desmute
            console.log('üñ•Ô∏è Habilitando √°udio da tela existente...');
            screenAudioTrack.track.enabled = true;
            setState(prev => ({ ...prev, isScreenAudioEnabled: true }));
          } else {
            // Reiniciar screen share com √°udio
            console.log('üñ•Ô∏è Reiniciando screen share com √°udio...');
            callObjectRef.current.stopScreenShare();
            setTimeout(() => {
              callObjectRef.current?.startScreenShare({ audio: true });
            }, 100);
            setState(prev => ({ 
              ...prev, 
              isScreenAudioEnabled: true,
              isScreenAudioCaptured: true 
            }));
          }
        } else {
          // Desligar apenas o √°udio da tela
          if (screenAudioTrack?.track) {
            console.log('üñ•Ô∏è Desabilitando √°udio da tela (mantendo v√≠deo)...');
            screenAudioTrack.track.enabled = false;
            setState(prev => ({ ...prev, isScreenAudioEnabled: false }));
          } else {
            console.log('üñ•Ô∏è Reiniciando screen share sem √°udio...');
            // Se n√£o conseguir controlar o track diretamente, reiniciar sem √°udio
            callObjectRef.current.stopScreenShare();
            setTimeout(() => {
              callObjectRef.current?.startScreenShare({ audio: false });
            }, 100);
            setState(prev => ({ 
              ...prev, 
              isScreenAudioEnabled: false,
              isScreenAudioCaptured: true // Mant√©m screen share ativo
            }));
          }
        }
      } catch (error) {
        console.error('‚ùå Erro ao controlar √°udio da tela:', error);
        setState(prev => ({ ...prev, isScreenAudioEnabled: !nextState })); // Reverter estado
      }
    } else {
      setState(prev => ({ ...prev, isScreenAudioEnabled: nextState }));
    }
    
    console.log(`üñ•Ô∏è √Åudio da tela foi ${nextState ? 'LIGADO' : 'DESLIGADO'}`);
  }, [state.isScreenAudioEnabled, state.isScreenAudioCaptured]);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      if (callObjectRef.current) {
        try {
          callObjectRef.current.destroy();
        } catch (error) {
          console.warn('‚ö†Ô∏è Erro ao destruir CallObject:', error);
        }
      }
      if (audioLevelIntervalRef.current) {
        clearInterval(audioLevelIntervalRef.current);
      }
      // Limpar cache de deduplica√ß√£o
      processedMessagesRef.current.clear();
      processedInterimRef.current.clear();
    };
  }, []);

  // Atualizar dispositivos dispon√≠veis no mount
  useEffect(() => {
    updateAvailableDevices();
    
    // Escutar mudan√ßas de dispositivos - verificar disponibilidade
    if (navigator.mediaDevices && navigator.mediaDevices.addEventListener) {
      navigator.mediaDevices.addEventListener('devicechange', updateAvailableDevices);
      
      return () => {
        if (navigator.mediaDevices && navigator.mediaDevices.removeEventListener) {
          navigator.mediaDevices.removeEventListener('devicechange', updateAvailableDevices);
        }
      };
    }
  }, [updateAvailableDevices]);



  // Retorno compat√≠vel com useDeepgramTranscription + DUAL STREAM enhancements
  return {
    ...state,
    startListening,
    stopListening,
    pauseListening,
    resumeListening,
    forceFinalize,
    clearTranscript,
    // Fun√ß√µes adicionais espec√≠ficas Daily
    updateAvailableDevices,
    // NOVO: Fun√ß√£o de limpeza de hist√≥rico
    clearTranscriptionHistory,
    // FASE 2: Novos estados e fun√ß√µes de controle
    isMicrophoneEnabled: state.isMicrophoneEnabled,
    isScreenAudioEnabled: state.isScreenAudioEnabled,
    toggleMicrophone,
    toggleScreenAudio
  };
}; 