import { useState, useCallback, useRef, useEffect } from 'react';
import { useUser } from '@clerk/nextjs';
import DailyIframe, { 
  DailyCall, 
  DailyEvent
} from '@daily-co/daily-js';

// Interface para blocos de transcri√ß√£o (Fase 2)
interface TranscriptionBlock {
  id: string; // Ex: `block-${Date.now()}`
  source: 'microphone' | 'screen' | 'remote';
  color: 'blue' | 'green' | 'gray';
  startTime: Date;
  text: string; // O texto consolidado do bloco
}

// Interface para callback de mirror events
export interface MirrorCallbacks {
  onTrackAvailable?: () => void;
  onTrackUnavailable?: () => void;
}

// Interface compat√≠vel com Deepgram (mantendo mesma estrutura) + Enhanced Dual Stream
export interface TranscriptionState {
  transcript: string;
  interimTranscript: string;
  isListening: boolean;
  isConnected: boolean;
  isProcessing: boolean;
  error: string | null;
  connectionQuality: 'good' | 'poor' | 'disconnected';
  audioLevel: number;
  wordsTranscribed: number;
  sessionDuration: number;
  lastActivity: Date | null;
  canForceFinalize: boolean;
  devicePermissions: {
    microphone: boolean;
    speaker: boolean;
  };
  availableDevices: {
    microphones: MediaDeviceInfo[];
    speakers: MediaDeviceInfo[];
  };
  selectedDeviceId: string | null;
  isScreenAudioCaptured: boolean;
  transcriptionLanguage: string;
  confidence: number;
  isPaused: boolean;
  segments: Array<{
    text: string;
    confidence: number;
    timestamp: Date;
    isFinal: boolean;
    audioSource: 'screen' | 'microphone' | 'remote';
    color: 'green' | 'blue' | 'gray';
    speakerId?: string; // NOVO: ID do speaker via diariza√ß√£o
    trackType?: 'audio' | 'screenAudio'; // NOVO: Tipo de track do Daily.co
  }>;
  blocks: TranscriptionBlock[]; // NOVO: Sistema de blocos (Fase 2)
  // NOVOS CAMPOS para Dual Stream Enhancement
  trackInfo: {
    audioTrackActive: boolean;
    screenAudioTrackActive: boolean;
    lastDetectedSource: 'microphone' | 'screen' | 'unknown';
  };
  diarizationEnabled: boolean;
  speakerStats: {
    microphoneSegments: number;
    screenSegments: number;
    totalSpeakers: number;
  };
  // NOVOS CAMPOS para Controles Independentes (Fase 2)
  isMicrophoneEnabled: boolean;
  isScreenAudioEnabled: boolean;
}

// Interface para configura√ß√£o Daily
interface DailyTranscriptionConfig {
  language?: string;
  model?: string;
  profanityFilter?: boolean;
  enableScreenAudio?: boolean;
  enableInterimResults?: boolean;
}

// Interface para eventos de transcri√ß√£o Daily
interface DailyTranscriptionMessage {
  type: 'transcription-message';
  sessionId: string;
  participantId: string;
  text: string;
  timestamp: string;
  is_final: boolean;
  confidence?: number;
  language?: string;
}

// Fun√ß√£o para diagnosticar disponibilidade de APIs
const checkMediaDevicesSupport = () => {
  const support = {
    mediaDevices: !!navigator.mediaDevices,
    getUserMedia: !!(navigator.mediaDevices?.getUserMedia),
    enumerateDevices: !!(navigator.mediaDevices?.enumerateDevices),
    addEventListener: !!(navigator.mediaDevices?.addEventListener),
    isSecureContext: !!window.isSecureContext,
    protocol: window.location.protocol
  };
  
  console.log('üìã Diagn√≥stico MediaDevices:', support);
  return support;
};

export const useDailyTranscription = (config?: DailyTranscriptionConfig & { mirrorCallbacks?: MirrorCallbacks }) => {
  // Hook para acessar dados do usu√°rio Clerk
  const { user, isLoaded: isUserLoaded } = useUser();

  // Diagn√≥stico inicial - executar apenas uma vez
  useEffect(() => {
    checkMediaDevicesSupport();
  }, []);

  // Estados principais compat√≠veis com Deepgram + Enhanced Dual Stream
  const [state, setState] = useState<TranscriptionState>({
    transcript: '',
    interimTranscript: '',
    isListening: false,
    isConnected: false,
    isProcessing: false,
    error: null,
    connectionQuality: 'disconnected',
    audioLevel: 0,
    wordsTranscribed: 0,
    sessionDuration: 0,
    lastActivity: null,
    canForceFinalize: true,
    devicePermissions: {
      microphone: false,
      speaker: false
    },
    availableDevices: {
      microphones: [],
      speakers: []
    },
    selectedDeviceId: null,
    isScreenAudioCaptured: false,
    transcriptionLanguage: config?.language || 'pt',
    confidence: 0,
    isPaused: false,
    segments: [],
    blocks: [], // NOVO: Sistema de blocos inicializado (Fase 2)
    // NOVOS CAMPOS INICIALIZADOS
    trackInfo: {
      audioTrackActive: false,
      screenAudioTrackActive: false,
      lastDetectedSource: 'unknown'
    },
    diarizationEnabled: true, // Ativado por padr√£o
    speakerStats: {
      microphoneSegments: 0,
      screenSegments: 0,
      totalSpeakers: 0
    },
    // NOVOS CAMPOS INICIALIZADOS (Fase 2)
    isMicrophoneEnabled: false, // Microfone inicia desligado
    isScreenAudioEnabled: true   // √Åudio da tela inicia ligado
  });

  // Refs para Daily.co
  const callObjectRef = useRef<DailyCall | null>(null);
  const roomNameRef = useRef<string | null>(null);
  const startTimeRef = useRef<Date | null>(null);
  const audioLevelIntervalRef = useRef<NodeJS.Timeout | null>(null);
  
  
  // Sistema de deduplica√ß√£o espec√≠fico para nosso contexto (1 usu√°rio, 2 canais)
  const processedMessagesRef = useRef<Map<string, number>>(new Map());
  const processedInterimRef = useRef<Map<string, number>>(new Map()); // Cache separado para interim
  const MESSAGE_CLEANUP_INTERVAL = 10000; // 10s cleanup

  // NOVA FUN√á√ÉO: Determinar fonte de √°udio - ESTRAT√âGIA BASEADA EM DADOS REAIS
  const determineAudioSourceAdvanced = useCallback((data: any, participants: any): {
    audioSource: 'screen' | 'microphone' | 'remote';
    trackType: 'audio' | 'screenAudio';
    confidence: number;
  } => {
    // CORRE√á√ÉO: Tentar ambos os formatos de campo (trackType e track_type)
    const trackTypeValue = data.trackType || data.track_type;
    const speakerIdValue = data.speaker || data.speaker_id;
    
    console.log('üî¨ An√°lise otimizada (FASE 1 - CORRIGIDA):', {
      trackType: trackTypeValue,
      speakerId: speakerIdValue,
      availableFields: Object.keys(data),
      rawTrackType: data.trackType,
      rawTrack_type: data.track_type
    });

    // ü•á CAMADA 1: trackType (PRIORIDADE M√ÅXIMA - CORRIGIDA)
    if (trackTypeValue) {
      const sourceMap = {
        'screen-audio': { audioSource: 'screen' as const, trackType: 'screenAudio' as const },
        'cam-audio': { audioSource: 'microphone' as const, trackType: 'audio' as const },
        'screenAudio': { audioSource: 'screen' as const, trackType: 'screenAudio' as const },
        'audio': { audioSource: 'microphone' as const, trackType: 'audio' as const }
      };
      
      const mapping = sourceMap[trackTypeValue as keyof typeof sourceMap];
      if (mapping) {
        console.log('‚úÖ Fonte detectada via trackType (CORRIGIDA):', {
          campo: trackTypeValue,
          resultado: mapping,
          confianca: '95%'
        });
        return { ...mapping, confidence: 0.95 };
      }
      
      // Fallback para valores desconhecidos mas que contenham informa√ß√£o √∫til
      console.log('‚ö†Ô∏è trackType desconhecido:', trackTypeValue);
    }

    // ü•à CAMADA 2: speaker_id (OFICIAL - BACKUP)
    if (speakerIdValue) {
      console.log('üé≠ Detectando fonte via speaker ID (BACKUP):', speakerIdValue);
      
      // Estrat√©gia: speaker IDs diferentes = fontes diferentes
      // Speaker 0 ou primeiro = microfone, Speaker 1+ = tela
      const isFirstSpeaker = speakerIdValue === '0' || speakerIdValue === 0 || speakerIdValue === 'speaker_0';
      
      if (state.isScreenAudioCaptured && !isFirstSpeaker) {
        return {
          audioSource: 'screen',
          trackType: 'screenAudio',
          confidence: 0.85
        };
      }
    }

    // ü•â CAMADA 3: tracks analysis (T√âCNICO - BACKUP)
    const localParticipant = participants?.local;
    if (localParticipant?.tracks) {
      const audioTrack = localParticipant.tracks.audio;
      const screenAudioTrack = localParticipant.tracks.screenAudio;
      
      const audioActive = audioTrack?.state === 'sendable' || audioTrack?.state === 'loading';
      const screenAudioActive = screenAudioTrack?.state === 'sendable' || screenAudioTrack?.state === 'loading';
      
      console.log('üéµ Status dos tracks:', { audioActive, screenAudioActive });
      
      // Atualizar trackInfo no estado
      setState(prev => ({
        ...prev,
        trackInfo: {
          audioTrackActive: audioActive,
          screenAudioTrackActive: screenAudioActive,
          lastDetectedSource: screenAudioActive && state.isScreenAudioCaptured ? 'screen' : 'microphone'
        }
      }));
      
      // Se apenas screen audio est√° ativo
      if (screenAudioActive && !audioActive && state.isScreenAudioCaptured) {
        return {
          audioSource: 'screen',
          trackType: 'screenAudio',
          confidence: 0.80
        };
      }
    }

    // üèÖ CAMADA 4: content heuristics (√öltimo RECURSO)
    if (state.isScreenAudioCaptured) {
      console.log('üîÑ Usando heur√≠sticas de conte√∫do (√öltimo recurso)');
      
      // Estrat√©gia baseada em caracter√≠sticas do texto ou timestamp
      const textLength = data.text?.length || 0;
      const isLongText = textLength > 30; // Textos longos podem ser da tela (leitura)
      const timestampBased = Math.floor(Date.now() / 2000) % 2 === 0; // Alternar a cada 2 segundos
      
      // Combina√ß√£o de fatores
      const isScreenSource = isLongText || timestampBased;
      
      return {
        audioSource: isScreenSource ? 'screen' : 'microphone',
        trackType: isScreenSource ? 'screenAudio' : 'audio',
        confidence: 0.6
      };
    }

    // 5. FINAL: Default para microfone
    console.log('üé§ Defaulting para microfone');
    return {
      audioSource: 'microphone',
      trackType: 'audio',
      confidence: 0.8
    };
  }, [state.isScreenAudioCaptured]);

  // Atualizar dura√ß√£o da sess√£o
  useEffect(() => {
    let interval: NodeJS.Timeout;
    
    if (state.isListening && startTimeRef.current) {
      interval = setInterval(() => {
        const now = new Date();
        const duration = Math.floor((now.getTime() - startTimeRef.current!.getTime()) / 1000);
        setState(prev => ({ ...prev, sessionDuration: duration }));
      }, 1000);
    }
    
    return () => {
      if (interval) clearInterval(interval);
    };
  }, [state.isListening]);

  // Fun√ß√£o para obter permiss√µes de m√≠dia
  const requestPermissions = useCallback(async () => {
    try {
      // Verificar se getUserMedia est√° dispon√≠vel
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        console.error('‚ùå getUserMedia n√£o dispon√≠vel - verifique se est√° em HTTPS');
        setState(prev => ({
          ...prev,
          error: 'Acesso ao microfone n√£o dispon√≠vel (necess√°rio HTTPS)',
          devicePermissions: {
            ...prev.devicePermissions,
            microphone: false
          }
        }));
        return false;
      }

      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: true,
        video: false 
      });
      
      stream.getTracks().forEach(track => track.stop());
      
      setState(prev => ({
        ...prev,
        devicePermissions: {
          ...prev.devicePermissions,
          microphone: true
        }
      }));
      
      return true;
    } catch (error) {
      console.error('‚ùå Erro ao obter permiss√µes:', error);
      setState(prev => ({
        ...prev,
        error: 'Permiss√£o de microfone negada ou n√£o dispon√≠vel',
        devicePermissions: {
          ...prev.devicePermissions,
          microphone: false
        }
      }));
      
      return false;
    }
  }, []);

  // Fun√ß√£o para listar dispositivos dispon√≠veis
  const updateAvailableDevices = useCallback(async () => {
    try {
      // Verificar se mediaDevices est√° dispon√≠vel
      if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {
        console.warn('‚ö†Ô∏è navigator.mediaDevices n√£o dispon√≠vel');
        return;
      }

      const devices = await navigator.mediaDevices.enumerateDevices();
      
      setState(prev => ({
        ...prev,
        availableDevices: {
          microphones: devices.filter(d => d.kind === 'audioinput'),
          speakers: devices.filter(d => d.kind === 'audiooutput')
        }
      }));
    } catch (error) {
      console.error('‚ùå Erro ao listar dispositivos:', error);
    }
  }, []);

  // Monitorar n√≠vel de √°udio
  const startAudioLevelMonitoring = useCallback((callObject: DailyCall) => {
    if (audioLevelIntervalRef.current) {
      clearInterval(audioLevelIntervalRef.current);
    }

    audioLevelIntervalRef.current = setInterval(async () => {
      try {
        const stats = await callObject.getNetworkStats();
        const localAudio = stats?.stats?.latest?.recvBitsPerSecond || 0;
        
        setState(prev => ({
          ...prev,
          audioLevel: Math.min(100, Math.max(0, localAudio / 1000)) // Converter para 0-100
        }));
      } catch (error) {
        // Silencioso - estat√≠sticas podem n√£o estar dispon√≠veis
      }
    }, 100);
  }, []);

  // Handler otimizado para transcri√ß√£o iniciada
  const handleTranscriptionStarted = useCallback((event: any) => {
    console.log('‚úÖ Transcri√ß√£o Daily.co iniciada:', event);
    setState(prev => ({ 
      ...prev, 
      isListening: true,
      isProcessing: false, // CORRE√á√ÉO: resetar isProcessing quando transcri√ß√£o realmente inicia
      lastActivity: new Date()
    }));
  }, []);

  // Handler otimizado para erro de transcri√ß√£o COM RETRY
  const handleTranscriptionError = useCallback(async (event: any) => {
    console.error('‚ùå Erro de transcri√ß√£o:', event);
    
    // Se for erro 403, tentar com configura√ß√£o ainda mais simples
    if (event.errorMsg?.includes('403') || event.errorMsg?.includes('Unexpected server response')) {
      console.log('üîÑ Tentando reconectar com configura√ß√£o b√°sica...');
      
      try {
        const callObject = callObjectRef.current;
        if (callObject) {
          // Aguardar um pouco antes da tentativa
          await new Promise(resolve => setTimeout(resolve, 1000));
          
          // Configura√ß√£o m√≠nima v√°lida
          const basicConfig = {
            language: 'pt-BR',
            model: 'nova-2-general'
          };
          
          await callObject.startTranscription(basicConfig);
          
          setState(prev => ({
            ...prev,
            error: 'Reconectado com configura√ß√£o b√°sica - diariza√ß√£o limitada',
            isListening: true,
            isProcessing: false
          }));
          
          console.log('‚úÖ Reconectado com configura√ß√£o b√°sica');
          return;
        }
      } catch (retryError) {
        console.error('‚ùå Falha na reconex√£o:', retryError);
      }
    }
    
    setState(prev => ({
      ...prev,
      error: `Erro de transcri√ß√£o: ${event.errorMsg || 'Erro desconhecido'}`,
      isListening: false,
      isProcessing: false
    }));
  }, []);

  // Sistema de deduplica√ß√£o para nosso contexto espec√≠fico
  const isDuplicateMessage = useCallback((data: any) => {
    const now = Date.now();
    const isInterim = !data.is_final;
    
    // Gerar chave √∫nica baseada no conte√∫do e contexto
    // Para nosso caso: 1 usu√°rio com 2 canais (microfone + tela)
    const messageKey = `${data.text?.trim()}_${data.is_final ? 'final' : 'interim'}_${data.timestamp || now}`;
    
    // Para mensagens interim, usar cache separado com chave mais espec√≠fica
    if (isInterim) {
      // Chave espec√≠fica para interim: conte√∫do + timestamp (mais sens√≠vel)
      const interimKey = `${data.text?.trim()}_interim`;
      
      if (processedInterimRef.current.has(interimKey)) {
        console.log('üîÑ Mensagem interim duplicada ignorada:', interimKey.substring(0, 50) + '...');
        return true;
      }
      
      // Limpar cache interim anterior (manter apenas o mais recente)
      processedInterimRef.current.clear();
      processedInterimRef.current.set(interimKey, now);
      
      return false;
    }
    
    // Para mensagens finais, usar cache normal
    if (processedMessagesRef.current.has(messageKey)) {
      console.log('üîÑ Mensagem final duplicada ignorada:', messageKey.substring(0, 50) + '...');
      return true;
    }
    
    // Adicionar ao cache de mensagens processadas
    processedMessagesRef.current.set(messageKey, now);
    
    // Cleanup autom√°tico - remover mensagens antigas (>10s)
    const cutoffTime = now - MESSAGE_CLEANUP_INTERVAL;
    for (const [key, timestamp] of Array.from(processedMessagesRef.current.entries())) {
      if (timestamp < cutoffTime) {
        processedMessagesRef.current.delete(key);
      }
    }
    
    return false;
  }, []);

  // Handler otimizado para mensagem de transcri√ß√£o com deduplica√ß√£o
  const handleTranscriptionMessage = useCallback((data: any) => {
    const startTime = performance.now();
    
    // Verificar duplicata antes de processar
    if (isDuplicateMessage(data)) {
      return; // Ignorar mensagem duplicada
    }
    
    console.log('üìù Transcri√ß√£o processada (√∫nica):', data);
    
    // DEBUG INTENSIVO: Analisar TODOS os dados dispon√≠veis
    const participants = callObjectRef.current?.participants();
    
    console.log('üîç DEBUG COMPLETO - Dados brutos:', {
      rawData: data,
      dataKeys: Object.keys(data),
      dataValues: Object.values(data),
      participantsExists: !!participants,
      localParticipant: participants?.local,
      localTracks: participants?.local?.tracks,
      isScreenCaptured: state.isScreenAudioCaptured,
      callObjectMethods: callObjectRef.current 
        ? (() => {
            const callObject = callObjectRef.current;
            if (!callObject) return [];
            return Object.getOwnPropertyNames(callObject)
              .filter(name => {
                const descriptor = Object.getOwnPropertyDescriptor(callObject, name);
                return descriptor && typeof descriptor.value === 'function';
              })
              .slice(0, 10);
          })()
        : []
    });
    
    // NOVA ESTRAT√âGIA: Usar fun√ß√£o avan√ßada de detec√ß√£o de fonte
    const sourceAnalysis = determineAudioSourceAdvanced(data, participants);
    
    const audioSource = sourceAnalysis.audioSource;
    const trackType = sourceAnalysis.trackType;
    const detectionConfidence = sourceAnalysis.confidence;
    
    // FASE 2: Estrat√©gia baseada nos logs (Mapeamento Otimizado)
    const getBlockColor = (audioSource: string, trackType: string) => {
      if (trackType === "screen-audio") return 'green';  // üü¢ Tela
      if (trackType === "cam-audio") return 'blue';      // üîµ Microfone
      if (trackType === "screenAudio") return 'green';   // üü¢ Tela (formato alternativo)
      if (trackType === "audio") return 'blue';          // üîµ Microfone (formato alternativo)
      if (audioSource === 'screen') return 'green';      // üü¢ Fallback tela
      if (audioSource === 'microphone') return 'blue';   // üîµ Fallback mic
      return 'gray';                                      // ‚ö´ Desconhecido
    };
    
    const color = getBlockColor(audioSource, trackType) as 'green' | 'blue' | 'gray';
    

    console.log('üìä Enhanced Debug Daily.co:', {
      data,
      sourceAnalysis,
      participants: participants?.local,
      trackInfo: state.trackInfo,
      speakerId: data.speaker_id || data.speaker,
      trackType: data.track_type,
      isScreenAudioCaptured: state.isScreenAudioCaptured,
      availableFields: Object.keys(data),
      participantTracks: participants?.local?.tracks
    });
    
    console.log(`üé§ Fonte detectada (Enhanced): ${audioSource} (${trackType}) - Confian√ßa: ${(detectionConfidence * 100).toFixed(1)}%`);
    
    const newSegment = {
      text: data.text,
      confidence: data.confidence || 0,
      timestamp: new Date(),
      isFinal: data.is_final || false,
      audioSource,
      color,
      speakerId: data.speaker_id || data.speaker || 'unknown', // NOVO: Speaker ID da diariza√ß√£o
      trackType // NOVO: Tipo de track detectado
    };

    setState(prev => {
      const updatedSegments = [...prev.segments, newSegment];
      
      // NOVO: Atualizar estat√≠sticas de speakers
      const newStats = {
        microphoneSegments: prev.speakerStats.microphoneSegments + (audioSource === 'microphone' ? 1 : 0),
        screenSegments: prev.speakerStats.screenSegments + (audioSource === 'screen' ? 1 : 0),
        totalSpeakers: new Set([...prev.segments.map(s => s.speakerId), newSegment.speakerId]).size
      };
      
      if (data.is_final) {
        // FASE 2: L√≥gica Otimizada de Separa√ß√£o de Blocos
        const lastBlock = prev.blocks[prev.blocks.length - 1];
        let updatedBlocks;
        
        // FASE 2: Fun√ß√µes auxiliares para separa√ß√£o inteligente
        const createNewBlock = (segment: any, blockId: string): TranscriptionBlock => ({
          id: blockId,
          text: segment.text,
          source: segment.audioSource,
          color: segment.color,
          startTime: segment.timestamp
        });
        
        const shouldCreateNewBlock = (lastBlock: any, newSegment: any) => {
          if (!lastBlock) return true;
          
          // ‚úÖ PRINCIPAL: Nova fonte = novo bloco (OBRIGAT√ìRIO)
          if (lastBlock.source !== newSegment.audioSource) {
            console.log('üîÑ CRIT√âRIO ATINGIDO: Mudan√ßa de fonte:', lastBlock.source, '‚Üí', newSegment.audioSource);
            return true;
          }
          
          // ‚úÖ SECUND√ÅRIO: Limite de caracteres = novo bloco (EVITAR BLOCOS GIGANTES)
          if (lastBlock.text.length > 500) {
            console.log('üìè CRIT√âRIO ATINGIDO: Limite de 500 caracteres:', lastBlock.text.length);
            return true;
          }
          
          // ‚ùå REMOVIDO: Pausa longa (estava criando blocos demais)
          // ‚ùå REMOVIDO: Novo speaker (muito sens√≠vel para mesmo usu√°rio)
          
          console.log('‚úÖ CONSOLIDANDO no bloco existente (mesma fonte):', lastBlock.source);
          return false;
        };
        
        // Aplicar l√≥gica de separa√ß√£o otimizada
        const shouldCreate = shouldCreateNewBlock(lastBlock, {
          audioSource,
          speakerId: newSegment.speakerId,
          timestamp: newSegment.timestamp
        });
        
        if (shouldCreate) {
          // CONDI√á√ÉO ATINGIDA: Criar um NOVO bloco
          const newBlock = createNewBlock({
            audioSource,
            color,
            text: data.text,
            timestamp: new Date()
          }, `block-${Date.now()}`);
          updatedBlocks = [...prev.blocks, newBlock];
          
          // FASE 2: Logs simplificados
          if (!lastBlock) {
            console.log('üÜï Primeiro bloco criado:', newBlock.id);
          } else {
            console.log('üÜï Novo bloco criado (FASE 2):', {
              id: newBlock.id,
              fonte: newBlock.source,
              cor: newBlock.color,
              motivo: lastBlock.source !== audioSource ? 'mudan√ßa de fonte' : 'limite de caracteres'
            });
          }
        } else {
          // FASE 2: Consolida√ß√£o inteligente no bloco existente
          const updatedBlock = {
            ...lastBlock,
            text: lastBlock.text + (lastBlock.text ? ' ' : '') + data.text
          };
          updatedBlocks = [...prev.blocks.slice(0, -1), updatedBlock];
          console.log('üìù Bloco consolidado (FASE 2):', {
            fonte: updatedBlock.source,
            tamanho: updatedBlock.text.length,
            cor: updatedBlock.color,
            palavras: updatedBlock.text.split(' ').length
          });
        }
        
        // Log para debug da Fase 4
        console.log('üîç Estado dos blocos (Fase 4):', JSON.stringify(updatedBlocks, null, 2));
        
        // Texto final - adicionar ao transcript principal
        const finalText = prev.transcript + (prev.transcript ? ' ' : '') + data.text;
        
        return {
          ...prev,
          transcript: finalText,
          interimTranscript: '', // Limpar interim
          segments: updatedSegments,
          blocks: updatedBlocks, // NOVO: Atualizar blocos
          wordsTranscribed: finalText.split(' ').length,
          lastActivity: new Date(),
          confidence: data.confidence || 0,
          speakerStats: newStats // NOVO: Estat√≠sticas atualizadas
        };
      } else {
        // Resultado interim - apenas atualizar interimTranscript (sem duplica√ß√£o visual)
        return {
          ...prev,
          interimTranscript: data.text,
          segments: updatedSegments,
          lastActivity: new Date(),
          confidence: data.confidence || 0,
          speakerStats: newStats // NOVO: Estat√≠sticas atualizadas
        };
      }
    });
    
    const endTime = performance.now();
    const processingTime = endTime - startTime;
    console.log(`‚ö° Tempo de processamento: ${processingTime.toFixed(2)}ms`);
  }, [isDuplicateMessage]);

  // Handlers de eventos Daily.co com performance otimizada
  const setupDailyEventHandlers = useCallback((callObject: DailyCall) => {
    // Evento de participante entrou
    callObject.on('joined-meeting', () => {
      console.log('‚úÖ Conectado √† sala Daily.co');
      setState(prev => ({ 
        ...prev, 
        isConnected: true,
        connectionQuality: 'good',
        error: null
      }));
    });

    // Evento de erro com tratamento espec√≠fico para transport
    callObject.on('error', (event) => {
      console.error('‚ùå Erro Daily.co:', event);
      
      // Tratamento espec√≠fico para erro de transport disconnected
      if (event.errorMsg?.includes('transport') || event.errorMsg?.includes('disconnected')) {
        console.log('üîÑ Detectado erro de transport, tentando reconex√£o...');
        setState(prev => ({
          ...prev,
          error: 'Reconectando...',
          connectionQuality: 'poor'
        }));
        
        // Tentar reconex√£o ap√≥s delay
        setTimeout(async () => {
          try {
            if (callObjectRef.current && state.isListening) {
              console.log('üîÑ Reiniciando transcri√ß√£o ap√≥s erro de transport...');
              await callObjectRef.current.startTranscription({
                language: 'pt-BR',
                model: 'nova-2-general',
                profanity_filter: false,
                endpointing: 100,
                extra: {
                  interim_results: true,
                  punctuate: true,
                  utterance_end_ms: 1000
                }
              });
              setState(prev => ({ ...prev, error: null, connectionQuality: 'good' }));
              console.log('‚úÖ Transcri√ß√£o reconectada com sucesso');
            }
          } catch (reconnectError) {
            console.error('‚ùå Falha na reconex√£o:', reconnectError);
            setState(prev => ({
              ...prev,
              error: 'Falha na reconex√£o - tente reiniciar',
              isListening: false,
              isConnected: false,
              connectionQuality: 'disconnected'
            }));
          }
        }, 3000);
      } else {
        // Outros erros
        setState(prev => ({
          ...prev,
          error: `Erro Daily.co: ${event.errorMsg || 'Erro desconhecido'}`,
          isListening: false,
          isConnected: false,
          connectionQuality: 'disconnected'
        }));
      }
    });

    // Handlers espec√≠ficos ultra-r√°pidos
    callObject.on('transcription-started', handleTranscriptionStarted);
    callObject.on('transcription-error', handleTranscriptionError);
    
    // Evento de transcri√ß√£o parada
    callObject.on('transcription-stopped', (event) => {
      console.log('‚èπÔ∏è Transcri√ß√£o Daily.co parada:', event);
      setState(prev => ({ ...prev, isProcessing: false }));
    });

    // HANDLER PRIM√ÅRIO: Evento dedicado transcription-message (RECOMENDADO)
    callObject.on('transcription-message', (event) => {
      console.log('üìù Transcription-message (prim√°rio):', event);
      try {
        handleTranscriptionMessage(event);
      } catch (error) {
        console.error('‚ùå Erro ao processar transcription-message:', error);
      }
    });

    // HANDLER BACKUP: app-message para redund√¢ncia com fallback condicional
    // Nosso contexto: 1 usu√°rio, 2 canais - n√£o precisa filtro por session_id
    callObject.on('app-message', (event) => {
      // Filtro b√°sico para mensagens de transcri√ß√£o
      if (event.fromId !== 'transcription' || !event.data) return;
      
      console.log('üìù App-message (backup/fallback):', event.data);
      try {
        // Sistema de deduplica√ß√£o j√° trata duplicatas automaticamente
        // Permite redund√¢ncia sem duplica√ß√£o visual
        handleTranscriptionMessage(event.data);
      } catch (error) {
        console.error('‚ùå Erro ao processar app-message backup:', error);
      }
    });

    // Monitorar qualidade da conex√£o
    callObject.on('network-quality-change', (event) => {
      // Daily.co agora usa threshold ao inv√©s de quality
      const threshold = (event as any).threshold || event.quality;
      setState(prev => ({
        ...prev,
        connectionQuality: threshold > 0.5 ? 'good' : 'poor'
      }));
    });

    // Iniciar monitoramento de √°udio
    startAudioLevelMonitoring(callObject);
  }, [startAudioLevelMonitoring, handleTranscriptionStarted, handleTranscriptionError, handleTranscriptionMessage]);



  // Fun√ß√£o para iniciar transcri√ß√£o (compat√≠vel com Deepgram)
  const startListening = useCallback(async () => {
    try {
      setState(prev => ({ ...prev, error: null, isProcessing: true }));
      
      // Timeout de seguran√ßa para garantir que isProcessing n√£o fique travado
      const timeoutId = setTimeout(() => {
        console.warn('‚ö†Ô∏è Timeout na conex√£o Daily.co - resetando isProcessing');
        setState(prev => ({ 
          ...prev, 
          isProcessing: false, 
          error: 'Timeout na conex√£o - tente novamente' 
        }));
      }, 30000); // 30 segundos timeout

      // Verificar se usu√°rio est√° carregado e logado
      if (!isUserLoaded || !user) {
        console.log('‚è≥ Aguardando dados do usu√°rio...');
        clearTimeout(timeoutId);
        setState(prev => ({ ...prev, error: 'Aguardando autentica√ß√£o do usu√°rio', isProcessing: false }));
        return;
      }

      // Verificar permiss√µes de microfone
      const hasPermissions = await requestPermissions();
      if (!hasPermissions) {
        clearTimeout(timeoutId);
        setState(prev => ({ ...prev, isProcessing: false }));
        return;
      }

      // 1. Verificar se j√° estamos conectados √† sala (reconex√£o)
      let callObject = callObjectRef.current;
      
      if (!callObject || !state.isConnected) {
        // Precisamos conectar √† sala primeiro
        
        // Criar sala com clerk-id
        const roomName = `transcription-${user.id}`;
        console.log(`üè† Verificando/criando sala persistente: ${roomName}`);

        // Verificar se sala j√° existe ou criar nova
        let roomData;
        try {
          const roomResponse = await fetch('/api/daily/rooms', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              roomName: roomName, // Nome espec√≠fico baseado no clerk ID
              language: config?.language || 'pt',
              transcriptionModel: config?.model || 'nova-2-general',
              enableTranscription: true
            })
          });

          if (!roomResponse.ok) {
            throw new Error('Erro ao criar/acessar sala Daily.co');
          }

          roomData = await roomResponse.json();
          roomNameRef.current = roomData.room.name;
          
          if (roomData.room.isExisting) {
            console.log(`üîÑ Reconectando √† sala existente: ${roomData.room.name}`);
          } else {
            console.log(`‚úÖ Nova sala criada: ${roomData.room.name}`);
          }

        } catch (error) {
          console.error('‚ùå Erro ao preparar sala:', error);
          clearTimeout(timeoutId);
          setState(prev => ({ ...prev, error: 'Erro ao preparar sala de confer√™ncia', isProcessing: false }));
          return;
        }

        // Criar token de acesso
        const tokenResponse = await fetch('/api/daily/tokens', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            roomName: roomData.room.name,
            userName: `${user.firstName || 'Usuario'}-${user.id.slice(-6)}`,
            enableTranscription: true,
            permissions: {
              canScreenshare: config?.enableScreenAudio !== false
            }
          })
        });

        if (!tokenResponse.ok) {
          throw new Error('Erro ao criar token Daily.co');
        }

        const tokenData = await tokenResponse.json();

        // Criar CallObject Daily.co
        callObject = DailyIframe.createCallObject({
          audioSource: true,
          videoSource: false
        });

        callObjectRef.current = callObject;

        // Setup event handlers
        setupDailyEventHandlers(callObject);

        // Entrar na sala
        await callObject.join({
          url: roomData.room.url,
          token: tokenData.token,
          userName: tokenData.userName
        });

        console.log(`‚úÖ Conectado √† sala ${roomData.room.name}`);
        
        setState(prev => ({
          ...prev,
          isConnected: true
        }));
      }

      // 2. Iniciar transcri√ß√£o com configura√ß√£o V√ÅLIDA (removendo par√¢metros n√£o suportados)
      console.log('üé§ Iniciando transcri√ß√£o com diariza√ß√£o (configura√ß√£o corrigida)...');
      const transcriptionConfig = {
        language: 'pt-BR',
        model: 'nova-2-general',
        profanity_filter: false, // N√£o filtrar em contexto business
        diarize: true, // ATIVADO: Identifica diferentes speakers
        punctuate: true, // Pontua√ß√£o autom√°tica melhora legibilidade
        endpointing: 100, // CR√çTICO: Reduz lat√™ncia de 300ms para 100ms
        extra: {
          endpointing: 100,
          interim_results: true,
          punctuate: true,
          utterance_end_ms: 1000,
          diarize: true
          // Removidos par√¢metros n√£o suportados: tier, multichannel, speaker_labels, detect_language, filler_words
        }
      };
      
      try {
        await callObject.startTranscription(transcriptionConfig);
        console.log('‚úÖ Transcri√ß√£o Daily.co iniciada com configura√ß√£o v√°lida');
      } catch (transcriptionError) {
        console.warn('‚ö†Ô∏è Erro ao iniciar transcri√ß√£o, tentando configura√ß√£o simplificada...', transcriptionError);
        // Fallback para configura√ß√£o mais simples
        try {
          await callObject.startTranscription({
            language: 'pt-BR',
            model: 'nova-2-general'
          });
          console.log('‚úÖ Transcri√ß√£o Daily.co iniciada com configura√ß√£o simplificada');
        } catch (fallbackError) {
          console.error('‚ùå Erro ao iniciar transcri√ß√£o mesmo com configura√ß√£o simplificada:', fallbackError);
          throw new Error('Falha ao iniciar transcri√ß√£o Daily.co');
        }
      }

      // 3. Configurar compartilhamento de tela se solicitado
      if (config?.enableScreenAudio) {
        try {
          console.log('üñ•Ô∏è Solicitando compartilhamento de tela...');
          callObject.startScreenShare({
            audio: true // Capturar √°udio da tela
          });
          // CORRE√á√ÉO: Estado s√≥ ser√° atualizado quando evento 'track-started' confirmar
          console.log('üîÑ Aguardando sele√ß√£o do usu√°rio para compartilhamento...');
        } catch (screenError) {
          console.warn('‚ö†Ô∏è Compartilhamento de tela n√£o dispon√≠vel:', screenError);
        }
      }

      // 4. Configurar estado inicial do microfone (desligado conforme planejamento)
      if (callObject) {
        console.log('üé§ Configurando microfone inicial como DESLIGADO...');
        callObject.setLocalAudio(false); // Desligar microfone no in√≠cio
      }

      startTimeRef.current = new Date();
      
      // Limpar timeout de seguran√ßa - conex√£o bem-sucedida
      clearTimeout(timeoutId);
      
      setState(prev => ({
        ...prev,
        isListening: true,
        isProcessing: false,
        transcript: '',
        interimTranscript: '',
        segments: [],
        wordsTranscribed: 0,
        sessionDuration: 0,
        // Garantir que estado inicial do microfone est√° correto
        isMicrophoneEnabled: false // Confirma estado inicial
      }));

      console.log('‚úÖ Transcri√ß√£o Daily.co iniciada com sucesso');

    } catch (error) {
      console.error('‚ùå Erro ao iniciar Daily.co:', error);
      
      // Limpar timeout de seguran√ßa - erro capturado
      clearTimeout(timeoutId);
      
      setState(prev => ({
        ...prev,
        error: error instanceof Error ? error.message : 'Erro ao iniciar transcri√ß√£o',
        isListening: false,
        isProcessing: false,
        isConnected: false
      }));
    }
  }, [user, isUserLoaded, state.isConnected, config, requestPermissions, setupDailyEventHandlers]);

  // Fun√ß√£o para parar transcri√ß√£o (compat√≠vel com Deepgram)
  const stopListening = useCallback(async () => {
    try {
      if (callObjectRef.current) {
        // Parar transcri√ß√£o
        await callObjectRef.current.stopTranscription();
        
        // Parar compartilhamento de tela se ativo
        if (state.isScreenAudioCaptured) {
          callObjectRef.current.stopScreenShare();
        }
        
        // Sair da sala
        await callObjectRef.current.leave();
        
        // Destruir call object
        callObjectRef.current.destroy();
        callObjectRef.current = null;
      }

      // Limpar intervalos
      if (audioLevelIntervalRef.current) {
        clearInterval(audioLevelIntervalRef.current);
        audioLevelIntervalRef.current = null;
      }

      setState(prev => ({
        ...prev,
        isListening: false,
        isConnected: false,
        isProcessing: false,
        connectionQuality: 'disconnected',
        audioLevel: 0,
        isScreenAudioCaptured: false
      }));

      console.log('‚úÖ Transcri√ß√£o Daily.co parada');

    } catch (error) {
      console.error('‚ùå Erro ao parar Daily.co:', error);
      setState(prev => ({
        ...prev,
        error: error instanceof Error ? error.message : 'Erro ao parar transcri√ß√£o'
      }));
    }
  }, [state.isScreenAudioCaptured]);

  // Pausar/retomar (compat√≠vel com Deepgram)
  const pauseListening = useCallback(async () => {
    // Daily.co n√£o tem pausa nativa, simular pausando o processamento
    setState(prev => ({ ...prev, isPaused: true }));
  }, []);

  const resumeListening = useCallback(async () => {
    setState(prev => ({ ...prev, isPaused: false }));
  }, []);

  // For√ßa finaliza√ß√£o (compat√≠vel com Deepgram)
  const forceFinalize = useCallback(async () => {
    if (callObjectRef.current && state.interimTranscript) {
      // Adicionar interim como final
      setState(prev => ({
        ...prev,
        transcript: prev.transcript + (prev.transcript ? ' ' : '') + prev.interimTranscript,
        interimTranscript: '',
        wordsTranscribed: (prev.transcript + ' ' + prev.interimTranscript).split(' ').length
      }));
    }
  }, [state.interimTranscript]);

  // Limpar estados (compat√≠vel com Deepgram)
  const clearTranscript = useCallback(() => {
    setState(prev => ({
      ...prev,
      transcript: '',
      interimTranscript: '',
      segments: [],
      wordsTranscribed: 0
    }));
  }, []);


  // NOVO: Fun√ß√£o de limpeza de hist√≥rico (preserva texto intermedi√°rio)
  const clearTranscriptionHistory = useCallback(() => {
    console.log('üßπ Limpando blocos finalizados. Texto intermedi√°rio ser√° preservado.');
    setState(prevState => ({
      ...prevState,
      blocks: [], // A√ß√£o principal: esvazia APENAS a lista de blocos.
      // O estado 'interimTranscript' e todos os outros s√£o intencionalmente preservados.
    }));
  }, []);

  // FASE 2: Fun√ß√µes de Controle de √Åudio Independentes
  
  // Fun√ß√£o para o microfone do usu√°rio
  const toggleMicrophone = useCallback(() => {
    const nextState = !state.isMicrophoneEnabled;
    callObjectRef.current?.setLocalAudio(nextState);
    setState(prev => ({ ...prev, isMicrophoneEnabled: nextState }));
    console.log(`üé§ Microfone foi ${nextState ? 'LIGADO' : 'DESLIGADO'}`);
  }, [state.isMicrophoneEnabled]);

  // Fun√ß√£o para o √°udio da tela
  const toggleScreenAudio = useCallback(() => {
    // CORRE√á√ÉO: Esta fun√ß√£o agora apenas controla o √°udio quando a tela j√° est√° sendo compartilhada
    if (!state.isScreenAudioCaptured) {
      console.log('‚ÑπÔ∏è Nenhuma tela est√° sendo compartilhada. Use o bot√£o COMPARTILHAR primeiro.');
      return;
    }

    const nextState = !state.isScreenAudioEnabled;
    
    if (callObjectRef.current) {
      try {
        const participants = callObjectRef.current.participants();
        const localParticipant = participants?.local;
        const screenAudioTrack = localParticipant?.tracks?.screenAudio;
        
        if (nextState) {
          // Ligar √°udio da tela existente
          if (screenAudioTrack?.track) {
            console.log('üîä Habilitando √°udio da tela...');
            screenAudioTrack.track.enabled = true;
            setState(prev => ({ ...prev, isScreenAudioEnabled: true }));
          } else {
            // Reiniciar screen share com √°udio
            console.log('üîä Reiniciando compartilhamento com √°udio...');
            callObjectRef.current.stopScreenShare();
            setTimeout(() => {
              callObjectRef.current?.startScreenShare({ audio: true });
            }, 100);
            // CORRE√á√ÉO: Estado ser√° atualizado pelos eventos track-started/stopped
            console.log('üîÑ Aguardando confirma√ß√£o do restart...');
          }
        } else {
          // Desligar apenas o √°udio da tela
          if (screenAudioTrack?.track) {
            console.log('üîá Desabilitando √°udio da tela (mantendo v√≠deo)...');
            screenAudioTrack.track.enabled = false;
            setState(prev => ({ ...prev, isScreenAudioEnabled: false }));
          } else {
            console.log('üîá Reiniciando compartilhamento sem √°udio...');
            callObjectRef.current.stopScreenShare();
            setTimeout(() => {
              callObjectRef.current?.startScreenShare({ audio: false });
            }, 100);
            // CORRE√á√ÉO: Estado ser√° atualizado pelos eventos track-started/stopped
            setState(prev => ({ 
              ...prev, 
              isScreenAudioEnabled: false
              // isScreenAudioCaptured ser√° gerenciado pelos eventos
            }));
          }
        }
      } catch (error) {
        console.error('‚ùå Erro ao controlar √°udio da tela:', error);
        setState(prev => ({ ...prev, isScreenAudioEnabled: !nextState })); // Reverter estado
      }
    } else {
      setState(prev => ({ ...prev, isScreenAudioEnabled: nextState }));
    }
    
    console.log(`üîä √Åudio da tela foi ${nextState ? 'LIGADO' : 'DESLIGADO'}`);
  }, [state.isScreenAudioEnabled, state.isScreenAudioCaptured]);

  // NOVA: Fun√ß√£o dedicada para controlar compartilhamento de tela
  const toggleScreenShare = useCallback(() => {
    if (!callObjectRef.current) {
      console.log('‚ö†Ô∏è N√£o conectado √† sala Daily.co');
      return;
    }

    const isCurrentlySharing = state.isScreenAudioCaptured;
    
    if (isCurrentlySharing) {
      // Parar compartilhamento - pode ser imediato pois sempre funciona
      console.log('üõë Parando compartilhamento de tela...');
      try {
        callObjectRef.current.stopScreenShare();
        // Estado ser√° atualizado pelo evento 'track-stopped'
        console.log('üîÑ Aguardando confirma√ß√£o de parada...');
      } catch (error) {
        console.error('‚ùå Erro ao parar compartilhamento:', error);
      }
    } else {
      // Iniciar compartilhamento - N√ÉO mudar estado aqui, aguardar evento 'track-started'
      console.log('üñ•Ô∏è Solicitando compartilhamento de tela...');
      try {
        callObjectRef.current.startScreenShare({ 
          audio: true // Iniciar com √°udio habilitado por padr√£o
        });
        console.log('üîÑ Aguardando sele√ß√£o do usu√°rio...');
        // IMPORTANTE: Estado s√≥ ser√° atualizado quando o evento 'track-started' confirmar
      } catch (error) {
        console.error('‚ùå Erro ao solicitar compartilhamento:', error);
      }
    }
  }, [state.isScreenAudioCaptured]);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      if (callObjectRef.current) {
        try {
          callObjectRef.current.destroy();
        } catch (error) {
          console.warn('‚ö†Ô∏è Erro ao destruir CallObject:', error);
        }
      }
      if (audioLevelIntervalRef.current) {
        clearInterval(audioLevelIntervalRef.current);
      }
      // Limpar cache de deduplica√ß√£o
      processedMessagesRef.current.clear();
      processedInterimRef.current.clear();
    };
  }, []);

  // Atualizar dispositivos dispon√≠veis no mount
  useEffect(() => {
    updateAvailableDevices();
    
    // Escutar mudan√ßas de dispositivos - verificar disponibilidade
    if (navigator.mediaDevices && navigator.mediaDevices.addEventListener) {
      navigator.mediaDevices.addEventListener('devicechange', updateAvailableDevices);
      
      return () => {
        if (navigator.mediaDevices && navigator.mediaDevices.removeEventListener) {
          navigator.mediaDevices.removeEventListener('devicechange', updateAvailableDevices);
        }
      };
    }
  }, [updateAvailableDevices]);

  // Fun√ß√£o para acessar o screen video track (ISOLADA - n√£o afeta transcri√ß√£o)
  const getScreenVideoTrack = useCallback(() => {
    if (!callObjectRef.current) {
      console.warn('üö´ Mirror: CallObject n√£o dispon√≠vel');
      return null;
    }
    
    try {
      const participants = callObjectRef.current.participants();
      const localParticipant = participants?.local;
      
      // ‚úÖ VALIDA√á√ÉO: Verificar se screen share est√° ativo
      if (!localParticipant?.tracks?.screenVideo) {
        console.warn('üö´ Mirror: Screen video track n√£o encontrado');
        return null;
      }
      
      const screenVideoTrack = localParticipant.tracks.screenVideo;
      
      // ‚úÖ SEGURAN√áA: Verificar se o track est√° dispon√≠vel e ativo
      // Aceitar estados "sendable" ou "playable" - ambos indicam que o track est√° funcional
      if (!screenVideoTrack.track || (screenVideoTrack.state !== 'sendable' && screenVideoTrack.state !== 'playable')) {
        console.warn('üö´ Mirror: Screen video track n√£o est√° ativo:', screenVideoTrack.state);
        return null;
      }
      
      console.log('‚úÖ Mirror: Screen video track encontrado:', {
        kind: screenVideoTrack.track.kind,
        enabled: screenVideoTrack.track.enabled,
        readyState: screenVideoTrack.track.readyState,
        state: screenVideoTrack.state
      });
      
      // ‚úÖ GARANTIA: Retorna APENAS o track de v√≠deo da tela compartilhada
      return screenVideoTrack.track;
      
    } catch (error) {
      console.error('‚ùå Mirror: Erro ao acessar screen video track:', error);
      return null;
    }
  }, []);

  // Fun√ß√£o para criar elemento de v√≠deo mirror com dimens√µes responsivas
  const createScreenMirror = useCallback((videoTrack: MediaStreamTrack) => {
    // Detectar tamanho da tela para responsividade
    const screenWidth = window.innerWidth;
    let mirrorWidth, mirrorHeight;
    
    if (screenWidth > 1200) {
      mirrorWidth = 400;
      mirrorHeight = 225;
    } else if (screenWidth > 768) {
      mirrorWidth = 320;
      mirrorHeight = 180;
    } else {
      mirrorWidth = 280;
      mirrorHeight = 158;
    }
    
    // Criar elemento de v√≠deo
    const videoElement = document.createElement('video');
    videoElement.id = 'screen-mirror-video';
    videoElement.srcObject = new MediaStream([videoTrack]);
    videoElement.autoplay = true;
    videoElement.muted = true;
    videoElement.playsInline = true;
    
    // Aplicar estilos responsivos
    videoElement.style.cssText = `
      width: 100%;
      height: auto;
      max-width: ${mirrorWidth}px;
      max-height: ${mirrorHeight}px;
      border-radius: 8px;
      background-color: var(--eerie-black, #171818);
      object-fit: contain;
      transition: all 0.3s ease;
    `;
    
    console.log('‚úÖ Mirror: Elemento de v√≠deo criado:', { width: mirrorWidth, height: mirrorHeight });
    return videoElement;
  }, []);

  // Fun√ß√£o para gerenciar mirror (isolada das outras funcionalidades)
  const manageScreenMirror = useCallback(() => {
    const videoTrack = getScreenVideoTrack();
    
    if (videoTrack && state.isScreenAudioCaptured) {
      console.log('üé• Mirror: Criando mirror com track dispon√≠vel');
      const mirrorElement = createScreenMirror(videoTrack);
      return mirrorElement;
    } else {
      console.log('üö´ Mirror: Condi√ß√µes n√£o atendidas para criar mirror');
      return null;
    }
  }, [getScreenVideoTrack, createScreenMirror, state.isScreenAudioCaptured]);

  // ‚ö†Ô∏è CR√çTICO: Listener isolado para mirror (n√£o interfere com transcri√ß√£o)
  useEffect(() => {
    if (!callObjectRef.current) return;
    
    const handleTrackStarted = (event: any) => {
      // ‚úÖ FILTRO ESPEC√çFICO: Apenas screenVideo tracks locais
      if (event.track?.kind === 'video' && 
          event.participant?.local) {
        console.log('üñ•Ô∏è Mirror: Screen video track iniciado:', event);
        
        // ‚úÖ ATUALIZAR ESTADO: Compartilhamento realmente confirmado
        setState(prev => ({ 
          ...prev, 
          isScreenAudioCaptured: true,
          isScreenAudioEnabled: true 
        }));
        console.log('‚úÖ Compartilhamento de tela confirmado!');
        
        // Notificar componente que track est√° dispon√≠vel (via callback personalizado)
        if (config?.mirrorCallbacks?.onTrackAvailable) {
          setTimeout(() => {
            config.mirrorCallbacks?.onTrackAvailable?.();
          }, 500); // Pequeno delay para garantir que o track esteja realmente pronto
        }
      }
    };
    
    const handleTrackStopped = (event: any) => {
      // ‚úÖ FILTRO ESPEC√çFICO: Apenas screenVideo tracks locais
      if (event.track?.kind === 'video' && 
          event.participant?.local) {
        console.log('üñ•Ô∏è Mirror: Screen video track parou:', event);
        
        // ‚úÖ ATUALIZAR ESTADO: Compartilhamento realmente parado
        setState(prev => ({ 
          ...prev, 
          isScreenAudioCaptured: false,
          isScreenAudioEnabled: false 
        }));
        console.log('‚úÖ Compartilhamento de tela parado!');
        
        // Notificar componente que track n√£o est√° mais dispon√≠vel
        if (config?.mirrorCallbacks?.onTrackUnavailable) {
          config.mirrorCallbacks.onTrackUnavailable();
        }
      }
    };
    
    // ‚úÖ NAMESPACE ISOLADO: Usar namespace espec√≠fico para evitar conflitos
    const mirrorEventHandlers = {
      'track-started': handleTrackStarted,
      'track-stopped': handleTrackStopped
    };
    
    // Adicionar listeners
    Object.entries(mirrorEventHandlers).forEach(([event, handler]) => {
      callObjectRef.current?.on(event as any, handler);
    });
    
    return () => {
      // Cleanup isolado
      if (callObjectRef.current) {
        Object.entries(mirrorEventHandlers).forEach(([event, handler]) => {
          callObjectRef.current?.off(event as any, handler);
        });
      }
    };
  }, [config?.mirrorCallbacks]); // Adicionar depend√™ncia dos callbacks

  // ‚úÖ FALLBACK: Verifica√ß√£o peri√≥dica para garantir sincroniza√ß√£o
  useEffect(() => {
    if (!state.isScreenAudioCaptured) return;
    
    const checkInterval = setInterval(() => {
      const videoTrack = getScreenVideoTrack();
      console.log('üîÑ Mirror: Verifica√ß√£o peri√≥dica - track dispon√≠vel:', !!videoTrack);
    }, 5000); // Verificar a cada 5 segundos
    
    return () => clearInterval(checkInterval);
  }, [state.isScreenAudioCaptured, getScreenVideoTrack]);

  // Retorno compat√≠vel com useDeepgramTranscription + DUAL STREAM enhancements
  return {
    ...state,
    startListening,
    stopListening,
    pauseListening,
    resumeListening,
    forceFinalize,
    clearTranscript,
    // Fun√ß√µes adicionais espec√≠ficas Daily
    updateAvailableDevices,
    // NOVO: Fun√ß√£o de limpeza de hist√≥rico
    clearTranscriptionHistory,
    // FASE 2: Novos estados e fun√ß√µes de controle
    isMicrophoneEnabled: state.isMicrophoneEnabled,
    isScreenAudioEnabled: state.isScreenAudioEnabled,
    toggleMicrophone,
    toggleScreenAudio,
    toggleScreenShare, // NOVA: Controle dedicado de compartilhamento
    // NOVAS fun√ß√µes para mirror
    getScreenVideoTrack,
    createScreenMirror,
    manageScreenMirror
  };
}; 